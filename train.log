max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
max_len: 133
max_len: 133
max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
========== fold: 0 training ==========
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
Used seed: 42
Used seed: 42
Used seed: 42
Used seed: 42
max_len: 133
max_len: 133
max_len: 133
max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
========== fold: 0 training ==========
========== fold: 0 training ==========
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
Used seed: 42
Used seed: 42
Used seed: 42
Used seed: 42
max_len: 133
max_len: 133
max_len: 133
max_len: 133
========== fold: 0 training ==========
========== fold: 0 training ==========
========== fold: 0 training ==========
========== fold: 0 training ==========
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
transformers.__version__: 4.19.4
Used seed: 42
Used seed: 42
Used seed: 42
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
Used seed: 42
max_len: 133
========== fold: 0 training ==========
torch.__version__: 1.10.1+cu113
tokenizers.__version__: 0.11.6
transformers.__version__: 4.19.4
Used seed: 42
max_len: 133
========== fold: 0 training ==========
